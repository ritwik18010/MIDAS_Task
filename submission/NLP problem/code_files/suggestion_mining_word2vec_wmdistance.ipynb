{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('/home/ritwik/Downloads/capston_ project_task/dataset/Subtask-A-master/V1.4_Training.csv',header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.read_csv('/home/ritwik/Downloads/capston_ project_task/dataset/Subtask-A-master/SubtaskA_Trial_Test_Labeled.csv',encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import num2words\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english')) \n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "stemmer=PorterStemmer()\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.rename(columns={0:'serial',1:'Sentence',2:'Suggestion_or_not'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to preprocess text by lemmatizing the words and by removing the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    text=text.lower()\n",
    "    token1=tokenizer.tokenize(text)\n",
    "    token=[]\n",
    "    for x in token1:\n",
    "        if x not in stop_words:\n",
    "            token.append(x)\n",
    "            #stemmed = [stemmer.stem(tokens) ]\n",
    "    lemmatiz=[lemmatizer.lemmatize(tokens) for tokens in token]\n",
    "    return lemmatiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Data in the paragraph form for applying word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para=[[] for i in range(len(df))]\n",
    "for i in range(len(df)):\n",
    "    text=df.iloc[i][1]\n",
    "    text=str(text)\n",
    "    para[i]=preprocess_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_para=Word2Vec(para, min_count=1)\n",
    "model_para.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity calculation using Word2vec and wmdistance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function calculates the similarity of each sentence in the training data with each sentence in the testing data and assigns the sentence to the class of the document having the maximum similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def get_answers():\n",
    "    prediction=[]\n",
    "    for j in range(1,100):\n",
    "        sent=preprocess_text(df_test.iloc[j][1])\n",
    "        count=0\n",
    "        min1=math.inf\n",
    "        for i in range(len(df)):\n",
    "            #calculating word mover's distance which calculates the distance between vectors by taking their contexts into account\n",
    "            distance=model_para.wmdistance(sent,para[i])\n",
    "            # calculating the mininmum possible distance with any sentence\n",
    "            if distance<min1:\n",
    "                min1=distance\n",
    "                result=df.iloc[i][2]\n",
    "            count=count+1\n",
    "        prediction.append(result)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=get_answers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truelabels=df_test.iloc[:, 2].tolist()\n",
    "\n",
    "count=0\n",
    "for i in range(len(p)):\n",
    "    if p[i]==truelabels[i]:\n",
    "        count=count+1\n",
    "print(count/len(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing to a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing results of top 100 testing files as it is taking a lot of time to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Result_Word2Vec', \"w\") as outfile:\n",
    "    for entries in p:\n",
    "        outfile.write(str(entries))\n",
    "        outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
